Last fall, Google Translate rolled out a new-and-improved artificial intelligence translation engine that it claimed was, at times, “nearly indistinguishable” from human translation. Jost Zetzsche could only roll his eyes. The German native had been working as a professional translator for 20 years, and he’d heard time and time again that his industry would be threatened by advances in automation. Every time, he’d found, the hype was overblown—and Google Translate’s makeover was no exception. It certainly wasn’t the key to translation, he thought.
But it was remarkably good. Google had spent the better part of 2016 reworking its translation tool to be powered by AI—and in doing so, it had created something unnervingly powerful. Google Translate, once known for producing stilted but passable translations, had begun producing fluid, highly accurate prose. The kind of output that, to the untrained eye, was nearly indistinguishable from human translation. A 15,000-word New York Times story hailed it as “the great AI awakening.” The engine quickly began learning new tricks, figuring out how to translate language pairs it hadn’t encountered before: If it could do English to Japanese and English to Korean, it could figure out Korean to Japanese. At last month’s Pixel 2 launch, Google took its ambitious agenda a step further, introducing wireless headphones that it promised could translate 40 languages in real-time.
Since IBM debuted its pioneering machine translation system in 1954, the notion of a flawless machine translator has captured the imagination of programmers and the public alike. Science fiction writers have seized upon the idea, serving up utopian visions ranging from Star Trek’s Universal Translator to The Hitchhiker’s Guide to the Galaxy’s Babel Fish. Human-level translation—fluent prose that captures the meaning of the source text—is a holy grail of machine learning: one of the “AI-complete” challenges that, if conquered, would indicate that a machine had reached a human level of intelligence. The fanfare around Google’s advances in neural machine translation implied that the grail was within reach—and, along with it, the moment when human workers become obsolete.
But translators have long been on the frontlines of AI-induced job panic, and they aren’t worried. In fact, some are delighted. For those that have seized on the potential of AI tools, productivity has skyrocketed, along with demand for their work.
Think of them as the canary in the white-collar coal mine. At the moment, they’re still singing. As deep learning burgeons, many industries are coming to grips with the fact that AI is indeed capable of tasks that were once regarded as deeply human. Unlike drivers and warehouse employees, knowledge workers aren’t in immediate danger of being displaced. But as AI becomes an essential part of their workflow, their jobs are changing—and there’s no guarantee that today’s helpful AI tools won’t become a threat in the future. This presents workers with a choice: Set aside your ego and embrace your new AI coworker, or get left behind.
We’re not living in the golden age of AI, but we are living in the golden age of AI-enhanced productivity. Call it the First Pass Era. AI is now powerful enough to make a solid first attempt at countless complex tasks, but it’s not so powerful that it seems threatening. For more thought-intensive, subjective work, we still need humans.
That labor shift is unfolding across industries. The Washington Post’s in-house AI, Heliograf, published some 850 stories last year, with human reporters and editors adding analysis and colorful details. In graphic design, AI tools can now generate a first pass at designs, leaving the final execution to human designers. In film and publishing, new tools promise to weed through slush piles in search of the next great hit, freeing up editors from the never-ending submissions queue. These AI tools are like plucky young assistants on steroids: They’re highly competent and prolific, but still need a seasoned manager to do the heavy intellectual lifting. And, of course, that manager has to get on board with working alongside machines to reap the benefits.
At Fennemore Craig, an Arizona-based corporate law firm, lawyers have jumped aboard the AI train, piloting a new technology from a startup called ROSS Intelligence. Using a combination of IBM Watson and proprietary algorithms, ROSS is the AI-driven successor to tools like LexisNexis: It combs through millions of pages of case law and writes up its findings in a draft memo. The process, which might take a human lawyer four days, takes ROSS roughly 24 hours. ROSS doesn’t suffer from exhaustion or burnout: The tool can pull infinite all-nighters without its work suffering as a consequence.
ROSS’s writing abilities, while serviceable, aren’t its standout characteristic. According to Blake Atkinson, a third-year associate at Fennemore Craig, its writing is at “level of about a first-year law student.” (Anthony Austin, a partner at the firm, is more generous: In his opinion, he says, ROSS is as good as some first or second year associates.) The tool generates clean memos, and while it’s no Hemingway, it offers up a functional first draft filled with summaries of applicable case law, some basic analysis, and a straightforward conclusion. A human lawyer then adds deeper analysis and punches up the language, making the text something that might actually be enjoyable to read—for a lawyer, at least. “It lets us get to the fun and juicy stuff,” says Austin. “When you’re like, ‘Good lord, I don't care about a steam engine in 1885, what I really want to do is write something fun and engaging so the judge or opposing counsel will think, Holy crap, I'm screwed.’”
Eventually, tools like ROSS will almost certainly diminish the need for human lawyers in the discovery process. It’s not clear how that will change hiring of entry-level lawyers, whose jobs are often based on slogging through old case law at odd hours. But deep analysis and compelling writing is still well outside of ROSS’s reach. And it’s critical to the startup’s success that lawyers not fear ROSS—after all, who wants to train their replacements? That’s why CEO Andrew Arruda touts ROSS as a productivity tool rather than an AI attorney; it allows lawyers to serve even more clients and focus on the interesting parts of their jobs. Austin puts it more succinctly: With the help of ROSS, he says, “you look like a rock star.”
For many translators, that AI-fueled high of superhuman productivity is nothing new. When Alessandro Cattelan began his career in translation in 2003, he could expect to earn about $175 a day for translating some 2,000 words. He used computer-assisted translation tools that occasionally offered suggestions for a phrase based on his previous work—but translation was a very manual process. Today, working in tandem with AI, a translator would now be expected to get through eight or ten thousand words in a day for the same amount of money (adjusted for inflation), Cattelan says. That process, known as post-editing machine translation (PEMT), involves letting the machine take the first pass, and then bringing in a human translator in to tidy up the language, check for improperly interpreted terminology, and make sure the tone, context, and cultural cues of the translation are all on point.
“You have to figure out which bits of your work can be replaced by the machine, and where you as a human can bring your value,” says Cattelan, who is now VP of operations at Translated, a company that develops AI-based translation tools. Since Translated started offering neural machine translation to its post-editing machine translators in April, it’s seen a significant productivity boost, particularly in languages such as German and Russian, which used to require extra adjustments thanks to their complex grammars.
PEMT isn’t new—the niche has been growing since at least the 1980s—but with the advent of neural machine translation, it is seeing more widespread adoption. According to market research firm Common Sense Advisory, demand for post-editing is expected to grow faster than any other segment of the language industry in the coming years, and enterprise translation will likely see double-digit growth over the next several years. Common Sense Advisory warns that “present methods cannot possibly keep up with [that level of growth], even if the language industry were to add new translators at a historically unprecedented rate.” Some say that working with machine translation is becoming mandatory: According to Spence Green, CEO of Lilt, a machine-assisted translation platform, machine translation “is a requirement now, whereas for older translators, they didn’t even have to use translation memory software.”
Charlotte Brasler, a Sydney-based translator, says that in the past year, machine translation tools have gotten so good that unless she’d be breaking confidentiality agreements by using them (a not-infrequent obstacle), she tends to welcome the leg up. Working with highly competent AI lets her take on more projects, and frees up time so that she can work on more creative texts, which machines have traditionally failed to translate.
But that, too, is changing: Brasler says that in the past year, since the addition of neural nets, Google Translate has gotten remarkably good at tackling things like sales and marketing materials, where translating involves using colorful language and interpreting idioms. Of course, the engine is no poet—but it is rapidly improving in areas that humans long assumed were impossible for a machine to conquer. And for workers who define themselves by their artistry, that is a difficult pill to swallow.
A technological leap will always bear holdouts. There will be people who can’t stand the thought of collaborating with machines, and who would rather bury their heads in their idea journals and pretend that nothing is changing. For those workers, this AI growth spurt is nothing short of an existential crisis. Sure, a computer can sift through data and maybe even piece together a basic sentence—but can it write prose that brings you to tears? Can it parse the nuance of an idiom, or scout the next bestselling novelist, or persuade a Supreme Court justice to change his mind?
Not yet, but it can help you get there. As some of the most creative industries begin to experiment with AI, they’re facing pushback. This past April, when The Black List (a network for connecting filmmakers and screenwriters) announced it would be partnering with an AI company called ScriptBook to evaluate some scripts, writers revolted. Brian Koppelman, executive producer of Billions, called the tool “offensive & gross.” The Black List quickly canceled its partnership with ScriptBook, which scans scripts for character analysis, target demographics, and box-office success, among other metrics. And though the startup has successfully partnered with two major movie studios, ScriptBook CEO Nadira Azermai says that most filmmakers haven’t yet been able to get over their fear of the tool.
“Years ago, people thought that when it comes to creativity we’re safe, because AI cannot become as creative as humans or as special as humans. It’s not true,” says Azermai. When industry folk accuse her of creating a tool to steal their jobs, she tells them that their jobs are indeed under threat—but not by AI. Rather, she says to the naysayers, “You’ll lose your job to people who have learned how to cooperate with machines. You will lose your job if you keep turning your head the other direction and pretending it doesn't exist.”
A similar tool is StoryFit, whose offerings include a box office prediction score, analysis of the script’s structure and style, and a reading of the story’s emotional makeup. As TJ Barrack explains it, his studio, Adaptive Studios, would never pass on a script solely because of something it saw in a StoryFit report—but his team might consider how to evolve the script based on what it learned. “[If] this is showing me that it may have problems in the marketplace based on these certain things, are there areas we can improve the story?” Barrack says. “Certain plot points we can adjust? Can we add more emotion here or there?”
People are just beginning to get past the hype of artificial intelligence and start looking specifically at how AI-driven tools might help their work. StoryFit CEO Monica Landers says that she’s recently started to see wariness about her company’s product wane. But she still has to tread cautiously. When I asked her about the company’s next steps, she was hesitant to answer: “If we start talking too far ahead, it still makes people nervous,” she says.
Understandably so: If we relinquish creativity and intuition as human traits, we have to completely rethink what it means to be human in the first place. Both skills suggest some sort of unknowable imagination or sixth sense. But in fact, machines are already highly creative, producing surprising, innovative artistic works: They’re taking photos, writing music, and creating surrealist art that might give Dali a run for his money. It’s only once they start doing so in a way that is deeply resonant with the human experience that we need to worry.
“Machines can be creative and they are creative,” says Pedro Domingos, professor of computer science at the University of Washington and author of The Master Algorithm. Intuition, meanwhile, is a knottier problem: It requires a deeper understanding of how people think and how the world functions. Tech’s best engineers haven’t yet figured out how to equip an AI with intuition; as long as that remains the case, humans will have the upper hand in the workplace. A lawyer needs to understand her target reader and all of the biases or predispositions that person might have; a translator needs to have a nuanced understanding of the two cultures whose languages he is transposing. “As soon as one of these tasks opens up onto the real world, that's where the machines fall behind and people do have an advantage—at least for the foreseeable future,” says Domingos.
With our AI coworkers, work begins to look suspiciously utopian. Machines take over the thankless tasks that were, until recently, too complex to be automated, and humans get to immerse themselves in the most creative and rewarding aspects of their jobs. But this is a pattern that we’ve seen before—a boom that could eventually go bust.
When ATMs were first rolled out in the late 1960s, many were surprised to see the number of bank tellers in the US double, and keep growing for decades. Freed up from the dreary tasks of withdrawing cash, tellers could turn their attention to helping customers with account questions or issuing cashier’s checks; as a result, they became more productive. But after all that growth, the number of bank tellers is now on the decline, thanks to the cumulative effect of technologies such as PayPal, smartphone banking, and the declining need for cash. It took a while, but technology has finally flipped from boon to bogeyman. To Andrew McAfee, co-director of MIT’s Initiative on the Digital Economy, the saga of the bank tellers is a cautionary tale. “If technology is augmenting work and creating jobs for a while, that doesn’t mean that it’s going to be doing that for all time,” he says. “We’ve seen this movie before.”
For the time being, however, the jobs of translators—and lawyers, and doctors, and journalists, and literary agents—are safe. Some would even say their jobs are better than ever. But we do now find ourselves in a strange position. We have to accept that artificial intelligence is rapidly mastering tasks that we have long deemed off-limits for machines. We have to come to terms with the fact that embracing AI is rapidly becoming be a prerequisite for excelling in many fields. We have to welcome these new AI coworkers, and correct them when they make mistakes—all the while acknowledging that at some point, we just might teach them enough that they start climbing up the corporate ladder.